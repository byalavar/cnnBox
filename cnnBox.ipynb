{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class boxFilters(nn.Module):\n",
    "    def __init__(self,a,b,c,d):\n",
    "        super(boxFilters, self).__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(1.0),requires_grad=True)\n",
    "        #self.a = nn.Parameter(torch.tensor(a))\n",
    "        #self.b = nn.Parameter(torch.tensor(b))\n",
    "        #self.c = nn.Parameter(torch.tensor(c))\n",
    "        #self.d = nn.Parameter(torch.tensor(d))\n",
    "        self.a = int(a)\n",
    "        self.b = int(b)\n",
    "        self.c = int(c)\n",
    "        self.d = int(d)\n",
    "        # self.a.requires_grad = False\n",
    "        # self.b.requires_grad = False\n",
    "        # self.c.requires_grad = False\n",
    "        # self.d.requires_grad = False\n",
    "\n",
    "\n",
    "    \n",
    "    def setAlpha(self,alpha):\n",
    "        self.alpha = nn.Parameter(torch.tensor(alpha),requires_grad=True)\n",
    "    \n",
    "    def setABCD(self,a,b,c,d):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "    \n",
    "    def printParams(self):\n",
    "        print(\"A:\",self.a,\"B:\",self.b,\"C:\",self.c,\"D:\",self.d, \"Alpha:\", self.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def forward(self, integral_image):\n",
    "        \n",
    "    #     H, W = integral_image.shape[-2:]\n",
    "\n",
    "    #     H = H - self.ogFilterSize + 1\n",
    "    #     W = W - self.ogFilterSize + 1\n",
    "    #     output = torch.zeros((integral_image.shape[0],integral_image.shape[1],H,W)).to(self.device)\n",
    "    #     for box_filter in self.box_filters:\n",
    "    #         a, b, c, d = int(box_filter.a), int(box_filter.b), int(box_filter.c), int(box_filter.d)\n",
    "    #         if b >= a and d >= c:  # Check if the box filter is valid\n",
    "    #             # Compute the sum within the box filter for each position in the image\n",
    "\n",
    "    #           if(self.reg):\n",
    "    #             print(\"Regular Conv\")  \n",
    "    #             for i in range(H):\n",
    "    #                 for j in range(W):\n",
    "    #                     # Define the boundaries\n",
    "                        \n",
    "    #                     tlCol = j + a -1\n",
    "    #                     tlRow = i + c -1\n",
    "\n",
    "    #                     trCol = j + b\n",
    "    #                     trRow = i + c -1\n",
    "\n",
    "\n",
    "    #                     blCol = j + a -1\n",
    "    #                     blRow = i + d\n",
    "\n",
    "    #                     brCol = j + b\n",
    "    #                     brRow = i + d\n",
    "\n",
    "    #                     #print(\"tlCol:\",tlCol,\"tlRow:\",tlRow,\"trCol:\",trCol,\"trRow:\",trRow,\"blCol:\",blCol,\"blRow:\",blRow,\"brCol:\",brCol,\"brRow:\",brRow)\n",
    "    #                     # Get the sum within the boundaries and add it to the output\n",
    "\n",
    "    #                     if(tlRow>=0 and tlCol>=0):\n",
    "    #                         tlVal = integral_image[..., tlRow, tlCol]\n",
    "    #                     else:\n",
    "    #                         tlVal = 0\n",
    "                        \n",
    "    #                     if(trRow>=0 and trCol>=0):\n",
    "    #                         trVal = integral_image[..., trRow, trCol]\n",
    "    #                     else:\n",
    "    #                         trVal = 0\n",
    "                        \n",
    "    #                     if(blRow>=0 and blCol>=0):\n",
    "    #                         blVal = integral_image[..., blRow, blCol]\n",
    "    #                     else:\n",
    "    #                         blVal = 0\n",
    "                        \n",
    "    #                     if(brRow>=0 and brCol>=0):\n",
    "    #                         brVal = integral_image[..., brRow, brCol]\n",
    "    #                     else:\n",
    "    #                         brVal = 0\n",
    "\n",
    "                            \n",
    "                        \n",
    "\n",
    "    #                     #print(integral_image[..., tlRow, tlCol])\n",
    "    #                     output[..., i, j] += brVal  + tlVal - trVal - blVal\n",
    "    #           else:\n",
    "    #                 print(\"SIMD Conv\")\n",
    "\n",
    "    #                 # Define the boundaries\n",
    "    #                 row_indices = torch.arange(H).unsqueeze(-1).to(self.device)\n",
    "    #                 col_indices = torch.arange(W).to(self.device)\n",
    "    #                 print(row_indices.shape,col_indices.shape)\n",
    "    #                 tlCol = col_indices + a - 1\n",
    "    #                 tlRow = row_indices + c - 1\n",
    "\n",
    "    #                 trCol = col_indices + b\n",
    "    #                 trRow = tlRow  # trRow and tlRow are the same\n",
    "\n",
    "    #                 blCol = tlCol  # blCol and tlCol are the same\n",
    "    #                 blRow = row_indices + d\n",
    "\n",
    "    #                 brCol = trCol  # brCol and trCol are the same\n",
    "    #                 brRow = blRow  # brRow and blRow are the same\n",
    "\n",
    "    #                 # Get the values at the boundaries\n",
    "                    \n",
    "    #                 tlVal = torch.where((tlRow < 0) | (tlCol < 0), 0, integral_image[..., tlRow, tlCol])\n",
    "    #                 trVal = torch.where((trRow < 0) | (trCol < 0), 0, integral_image[..., trRow, trCol])\n",
    "    #                 blVal = torch.where((blRow < 0) | (blCol < 0), 0, integral_image[..., blRow, blCol])\n",
    "    #                 brVal = torch.where((brRow < 0) | (brCol < 0), 0, integral_image[..., brRow, brCol])\n",
    "\n",
    "    #                 # Compute the output\n",
    "    #                 output.add_(brVal + tlVal - trVal - blVal)  # in-place addition\n",
    "\n",
    "                        \n",
    "            \n",
    "    #             #print(f\"Invalid box filter: a={a}, b={b}, c={c}, d={d}\")\n",
    "    #     return output\n",
    "\n",
    "\n",
    "\n",
    "    # def forward(self, integral_image):\n",
    "        \n",
    "    #     H, W = integral_image.shape[-2:]\n",
    "\n",
    "    #     H = H - self.ogFilterSize + 1\n",
    "    #     W = W - self.ogFilterSize + 1\n",
    "    #     #output = torch.zeros((integral_image.shape[0],integral_image.shape[1],H,W)).to(self.device)\n",
    "    #     # Define the boundaries\n",
    "    #     row_indices = torch.arange(H).unsqueeze(-1).unsqueeze(-1).to(self.device)  # shape: (H, 1, 1)\n",
    "    #     col_indices = torch.arange(W).unsqueeze(-1).unsqueeze(0).to(self.device)  # shape: (1, W, 1)\n",
    "    #    # print(row_indices.shape,col_indices.shape)\n",
    "    #     # a, b, c, d should be 1D tensors of shape (num_filters,)\n",
    "    #     # reshape them to (1, 1, num_filters)\n",
    "\n",
    "    #     #box_filters_tensor = torch.tensor([[int(box_filter.a), int(box_filter.b), int(box_filter.c), int(box_filter.d)] for box_filter in self.box_filters]).to(self.device)\n",
    "    #     box_filters_tensor = torch.tensor([[box_filter.a, box_filter.b, box_filter.c, box_filter.d] for box_filter in self.box_filters]).to(self.device)\n",
    "        \n",
    "        \n",
    "\n",
    "    #     a, b, c, d = box_filters_tensor[:, 0], box_filters_tensor[:, 1], box_filters_tensor[:, 2], box_filters_tensor[:, 3]\n",
    "        \n",
    "    #     a, b, c, d = a.unsqueeze(0).unsqueeze(0), b.unsqueeze(0).unsqueeze(0), c.unsqueeze(0).unsqueeze(0), d.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "    #     #box_filters_alpha = torch.tensor([[box_filter.alpha] for box_filter in self.box_filters]).to(self.device)\n",
    "    #     box_filters_alpha = torch.stack([box_filter.alpha for box_filter in self.box_filters]).to(self.device)\n",
    "    #     #print(\"Alpha Check:\",box_filters_alpha,box_filters_alpha1)\n",
    "    #     #print(\"dtype\",box_filters_alpha.dtype)\n",
    "    #     #print(\"CA Shape:\",col_indices.shape,a.shape)\n",
    "    #     tlCol = col_indices + a - 1  # broadcasting happens here\n",
    "    #     tlRow = row_indices + c - 1\n",
    "\n",
    "    #     trCol = col_indices + b\n",
    "    #     trRow = tlRow  # trRow and tlRow are the same\n",
    "\n",
    "    #     blCol = tlCol  # blCol and tlCol are the same\n",
    "    #     blRow = row_indices + d\n",
    "\n",
    "    #     brCol = trCol  # brCol and trCol are the same\n",
    "    #     brRow = blRow  # brRow and blRow are the same\n",
    "    #     #print(tlCol.shape,tlRow.shape,trCol.shape,trRow.shape,blCol.shape,blRow.shape,brCol.shape,brRow.shape)\n",
    "    #     # Get the values at the boundaries\n",
    "    #     tlVal = torch.where((tlRow < 0) | (tlCol < 0), 0, integral_image[..., tlRow, tlCol])\n",
    "    #     trVal = torch.where((trRow < 0) | (trCol < 0), 0, integral_image[..., trRow, trCol])\n",
    "    #     blVal = torch.where((blRow < 0) | (blCol < 0), 0, integral_image[..., blRow, blCol])\n",
    "    #     brVal = torch.where((brRow < 0) | (brCol < 0), 0, integral_image[..., brRow, brCol])\n",
    "    #     #print(brVal.shape,tlVal.shape,trVal.shape,blVal.shape)\n",
    "    #     # Compute the output\n",
    "    #     output = brVal + tlVal - trVal - blVal  # in-place addition\n",
    "    #     #output = output*self.box_filters[0].alpha\n",
    "    #     #print(output.shape,box_filters_alpha.shape)\n",
    "    #     #print(\"1:\",output)\n",
    "    #     output = output.permute(0, 1, 4, 2, 3)\n",
    "    #     #print(\"out:\",output.shape[2])\n",
    "    #     #box_filters_alpha = box_filters_alpha.view(1, 1, output.shape[2], 1, 1)\n",
    "    #     box_filters_alpha = box_filters_alpha.view(1, 1, -1, 1, 1)\n",
    "    #     output = output * box_filters_alpha\n",
    "    #     output = output.sum(dim=2)\n",
    "    #     #print(\"2:\",output)\n",
    "    #     return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxFilterConvolution(nn.Module):\n",
    "    def __init__(self, box_filters, ogFilterSize,reg,device):\n",
    "        super(BoxFilterConvolution, self).__init__()\n",
    "        self.box_filters = box_filters\n",
    "        self.ogFilterSize = ogFilterSize\n",
    "        self.reg = reg\n",
    "        self.device = device \n",
    " \n",
    "    def forward(self, integral_image):\n",
    "        \n",
    "        H, W = integral_image.shape[-2:]\n",
    "\n",
    "        H = H - self.ogFilterSize + 1\n",
    "        W = W - self.ogFilterSize + 1\n",
    "        #output = torch.zeros((integral_image.shape[0],integral_image.shape[1],H,W)).to(self.device)\n",
    "        # Define the boundaries\n",
    "        row_indices = torch.arange(H).unsqueeze(-1).unsqueeze(-1).to(self.device)  # shape: (H, 1, 1)\n",
    "        col_indices = torch.arange(W).unsqueeze(-1).unsqueeze(0).to(self.device)  # shape: (1, W, 1)\n",
    "       # print(row_indices.shape,col_indices.shape)\n",
    "        # a, b, c, d should be 1D tensors of shape (num_filters,)\n",
    "        # reshape them to (1, 1, num_filters)\n",
    "\n",
    "        #box_filters_tensor = torch.tensor([[int(box_filter.a), int(box_filter.b), int(box_filter.c), int(box_filter.d)] for box_filter in self.box_filters]).to(self.device)\n",
    "        box_filters_tensor = torch.tensor([[box_filter.a, box_filter.b, box_filter.c, box_filter.d] for box_filter in self.box_filters]).to(self.device)\n",
    "        \n",
    "        \n",
    "\n",
    "        a, b, c, d = box_filters_tensor[:, 0], box_filters_tensor[:, 1], box_filters_tensor[:, 2], box_filters_tensor[:, 3]\n",
    "        \n",
    "        a, b, c, d = a.unsqueeze(0).unsqueeze(0), b.unsqueeze(0).unsqueeze(0), c.unsqueeze(0).unsqueeze(0), d.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        #box_filters_alpha = torch.tensor([[box_filter.alpha] for box_filter in self.box_filters]).to(self.device)\n",
    "        box_filters_alpha = torch.stack([box_filter.alpha for box_filter in self.box_filters]).to(self.device)\n",
    "        #print(\"Alpha Check:\",box_filters_alpha,box_filters_alpha1)\n",
    "        #print(\"dtype\",box_filters_alpha.dtype)\n",
    "        #print(\"CA Shape:\",col_indices.shape,a.shape)\n",
    "        tlCol = col_indices + a - 1  # broadcasting happens here\n",
    "        tlRow = row_indices + c - 1\n",
    "\n",
    "        trCol = col_indices + b\n",
    "        trRow = tlRow  # trRow and tlRow are the same\n",
    "\n",
    "        blCol = tlCol  # blCol and tlCol are the same\n",
    "        blRow = row_indices + d\n",
    "\n",
    "        brCol = trCol  # brCol and trCol are the same\n",
    "        brRow = blRow  # brRow and blRow are the same\n",
    "        #print(tlCol.shape,tlRow.shape,trCol.shape,trRow.shape,blCol.shape,blRow.shape,brCol.shape,brRow.shape)\n",
    "        # Get the values at the boundaries\n",
    "        tlVal = torch.where((tlRow < 0) | (tlCol < 0), 0, integral_image[..., tlRow, tlCol])\n",
    "        trVal = torch.where((trRow < 0) | (trCol < 0), 0, integral_image[..., trRow, trCol])\n",
    "        blVal = torch.where((blRow < 0) | (blCol < 0), 0, integral_image[..., blRow, blCol])\n",
    "        brVal = torch.where((brRow < 0) | (brCol < 0), 0, integral_image[..., brRow, brCol])\n",
    "        #print(brVal.shape,tlVal.shape,trVal.shape,blVal.shape)\n",
    "        # Compute the output\n",
    "        output = brVal + tlVal - trVal - blVal  # in-place addition\n",
    "        #output = output*self.box_filters[0].alpha\n",
    "        #print(output.shape,box_filters_alpha.shape)\n",
    "        #print(\"1:\",output)\n",
    "        output = output.permute(0, 1, 4, 2, 3)\n",
    "        #print(\"out:\",output.shape[2])\n",
    "        #box_filters_alpha = box_filters_alpha.view(1, 1, output.shape[2], 1, 1)\n",
    "        box_filters_alpha = box_filters_alpha.view(1, 1, -1, 1, 1)\n",
    "        output = output * box_filters_alpha\n",
    "        output = output.sum(dim=2)\n",
    "        #print(\"2:\",output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# CNN Network with box filters\n",
    "class cnnBox(nn.Module):\n",
    "\n",
    "    def __init__(self, nBoxes, nChannels, reg,device,box_filters,ogFilterSize):\n",
    "        super(cnnBox, self).__init__()\n",
    "        self.boxes = nBoxes\n",
    "        self.nChannels = nChannels\n",
    "        \n",
    "        #self.boxes = nn.ModuleList([boxFilters(0,1,0,1) for _ in range(self.boxes)])\n",
    "        #n = 5  # replace with the desired number of module lists\n",
    "        self.boxes = nn.ModuleList([boxFilters(0,1,0,1) for _ in range(self.boxes)])\n",
    "        for i in range(0,nBoxes):\n",
    "\n",
    "            self.boxes[i].setABCD(box_filters[i][0],box_filters[i][1],box_filters[i][2],box_filters[i][3])\n",
    "        \n",
    "        self.conv = BoxFilterConvolution(self.boxes,ogFilterSize,reg,device)\n",
    "        #self.fc = nn.Linear(576,128)\n",
    "         \n",
    "\n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x0 = x[:,0,:,:].cumsum(dim=-2).cumsum(dim=-1)\n",
    "        #print(x0.shape)\n",
    "        x0 = x0.unsqueeze(1)\n",
    "        x0 = self.conv(x0)\n",
    "\n",
    "        x1 = x[:,1,:,:].cumsum(dim=-2).cumsum(dim=-1)\n",
    "        x1 = x1.unsqueeze(1)\n",
    "        x1 = self.conv(x1)\n",
    "\n",
    "        \n",
    "        x2 = x[:,2,:,:].cumsum(dim=-2).cumsum(dim=-1)\n",
    "        x2 = x2.unsqueeze(1)\n",
    "        x2 = self.conv(x2)\n",
    "        # #print(x0.shape,x1.shape,x2.shape)\n",
    "        x = torch.stack([x0,x1,x2],dim=1)\n",
    "        x = x.sum(dim=1)\n",
    "        #print(x.shape)\n",
    "        #x = x.to(torch.float)\n",
    "        #x = nn.Flatten()(x)\n",
    "        #x = self.fc(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxFiltersList = [[0,1,0,1],[0,1,0,1],[0,2,2,2]]\n",
    "# cBox = cnnBox(3,1,False,device,boxFiltersList,3)\n",
    "# cBox.boxes[1].setAlpha(2.0)\n",
    "\n",
    "# optimizer = torch.optim.Adam(cBox.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "# cBox = cBox.to(device)\n",
    "\n",
    "\n",
    "# a = a.to(device)\n",
    "\n",
    "# x=cBox(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BoxFilterConvolution(nn.Module):\n",
    "#     def __init__(self, box_filters, ogFilterShape,reg,device):\n",
    "#         super(BoxFilterConvolution, self).__init__()\n",
    "#         self.box_filters = box_filters\n",
    "#         self.ogFilterShape = ogFilterShape\n",
    "#         self.reg = reg\n",
    "#         self.device = device\n",
    "\n",
    "\n",
    "\n",
    "#     def forward(self, integral_image):\n",
    "        \n",
    "#         H, W = integral_image.shape[-2:]\n",
    "\n",
    "#         H = H - self.ogFilterShape[0] + 1\n",
    "#         W = W - self.ogFilterShape[1] + 1\n",
    "#         C = self.ogFilterShape[2]\n",
    "#         #print(C)\n",
    "#         #output = torch.zeros((integral_image.shape[0],integral_image.shape[1],H,W)).to(self.device)\n",
    "#         # Define the boundaries\n",
    "#         #row_indices = torch.arange(H).unsqueeze(-1).unsqueeze(-1).to(self.device)  # shape: (H, 1, 1)\n",
    "#         #col_indices = torch.arange(W).unsqueeze(-1).unsqueeze(0).to(self.device)  # shape: (1, W, 1)\n",
    "#         row_indices = torch.arange(H).unsqueeze(-1).unsqueeze(-1).unsqueeze(0).expand(C, H, 1, 1).to(self.device)  # shape: (C, H, 1, 1)\n",
    "#         col_indices = torch.arange(W).unsqueeze(-1).unsqueeze(0).unsqueeze(0).expand(C, 1, W, 1).to(self.device)  # shape: (C, 1, W, 1)\n",
    "#         #print(row_indices)\n",
    "#        # print(row_indices.shape,col_indices.shape)\n",
    "#         # a, b, c, d should be 1D tensors of shape (num_filters,)\n",
    "#         # reshape them to (1, 1, num_filters)\n",
    "\n",
    "#         #box_filters_tensor = torch.tensor([[int(box_filter.a), int(box_filter.b), int(box_filter.c), int(box_filter.d)] for box_filter in self.box_filters]).to(self.device)\n",
    "#         #box_filters_tensor = torch.tensor([[box_filter.a, box_filter.b, box_filter.c, box_filter.d] for box_filter in self.box_filters]).to(self.device)\n",
    "        \n",
    "#         box_filters_tensor = torch.tensor([[[box_filter.a, box_filter.b, box_filter.c, box_filter.d] for box_filter in sublist] for sublist in self.box_filters]).to(self.device)\n",
    "#         #print(box_filters_tensor.shape,box_filters_tensor,box_filters_tensor[:,:,0])\n",
    "#         a, b, c, d = box_filters_tensor[:,:, 0], box_filters_tensor[:,:, 1], box_filters_tensor[:,:, 2], box_filters_tensor[:,:, 3]\n",
    "        \n",
    "       \n",
    "#         a, b, c, d = a.unsqueeze(1).unsqueeze(1), b.unsqueeze(1).unsqueeze(1), c.unsqueeze(1).unsqueeze(1), d.unsqueeze(1).unsqueeze(1)\n",
    "#         #print(row_indices.shape,a.shape)\n",
    "#         #return\n",
    "#         #print(a,a.shape)\n",
    "#         #return\n",
    "#         #box_filters_alpha = torch.tensor([[box_filter.alpha] for box_filter in self.box_filters]).to(self.device)\n",
    "#         #box_filters_alpha = torch.stack([box_filter.alpha for box_filter in self.box_filters]).to(self.device)\n",
    "#         box_filters_alpha = torch.stack([torch.stack([box_filter.alpha for box_filter in sublist]) for sublist in self.box_filters]).to(self.device)\n",
    "#         #print(\"Alpha Check:\",box_filters_alpha,box_filters_alpha.shape)\n",
    "#         #print(col_indices.shape,a.shape)\n",
    "#         #return\n",
    "#         #print(\"dtype\",box_filters_alpha.dtype)\n",
    "#         #print(\"CA Shape:\",col_indices.shape,a.shape)\n",
    "#         tlCol = col_indices + a - 1  # broadcasting happens here\n",
    "#         tlRow = row_indices + c - 1\n",
    "\n",
    "#         trCol = col_indices + b\n",
    "#         trRow = tlRow  # trRow and tlRow are the same\n",
    "\n",
    "#         blCol = tlCol  # blCol and tlCol are the same\n",
    "#         blRow = row_indices + d\n",
    "\n",
    "#         brCol = trCol  # brCol and trCol are the same\n",
    "#         brRow = blRow  # brRow and blRow are the same\n",
    "#         #print(tlCol.shape,tlRow.shape,trCol.shape,trRow.shape,blCol.shape,blRow.shape,brCol.shape,brRow.shape)\n",
    "#         # Get the values at the boundaries\n",
    "#         tlVal = torch.where((tlRow < 0) | (tlCol < 0), 0, integral_image[..., tlRow, tlCol])\n",
    "#         trVal = torch.where((trRow < 0) | (trCol < 0), 0, integral_image[..., trRow, trCol])\n",
    "#         blVal = torch.where((blRow < 0) | (blCol < 0), 0, integral_image[..., blRow, blCol])\n",
    "#         brVal = torch.where((brRow < 0) | (brCol < 0), 0, integral_image[..., brRow, brCol])\n",
    "#         #print(brVal.shape,tlVal.shape,trVal.shape,blVal.shape)\n",
    "#         # Compute the output\n",
    "#         output = brVal + tlVal - trVal - blVal  # in-place addition\n",
    "#         #output = output*self.box_filters[0].alpha\n",
    "#         #print(output.shape,box_filters_alpha.shape)\n",
    "#         #print(\"1:\",output)\n",
    "        \n",
    "#         # while len(output.shape) > 5:\n",
    "#         #     print(output.shape)\n",
    "#         #     output = output.squeeze(0)\n",
    "#         #print(\"output:\",output.shape)\n",
    "#         output = output.squeeze(1)\n",
    "#         output = output.permute(0, 1, 4, 2, 3)\n",
    "#         #print(output)\n",
    "#         #print(\"out:\",output.shape[2])\n",
    "#         #box_filters_alpha = box_filters_alpha.view(1, 1, output.shape[2], 1, 1)\n",
    "#         #print(box_filters_alpha.shape)\n",
    "#         box_filters_alpha = box_filters_alpha.view(1, box_filters_alpha.shape[0], box_filters_alpha.shape[1], 1, 1)\n",
    "#         output = output * box_filters_alpha\n",
    "#         output = output.sum(dim=2)\n",
    "#         #print(output)\n",
    "#         #print(\"2:\",output)\n",
    "#         return output\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# # CNN Network with box filters\n",
    "# class cnnBox(nn.Module):\n",
    "\n",
    "#     def __init__(self, nBoxes, reg,device,box_filters,ogFilterSize):\n",
    "#         super(cnnBox, self).__init__()\n",
    "#         self.oxes = nBoxes\n",
    "#         self.nChannels = ogFilterSize[2]\n",
    "        \n",
    "#         #self.boxes = nn.ModuleList([boxFilters(0,1,0,1) for _ in range(self.boxes)])\n",
    "#         #n = 5  # replace with the desired number of module lists\n",
    "#         self.boxes = [nn.ModuleList([boxFilters(0,1,0,1) for _ in range(self.boxes)]) for _ in range(self.nChannels)]\n",
    "#         for i in range(0,self.nChannels):\n",
    "#          for j in range(0,nBoxes):\n",
    "#             self.boxes[i][j].setABCD(box_filters[i][j][0],box_filters[i][j][1],box_filters[i][j][2],box_filters[i][j][3])\n",
    "        \n",
    "#         self.conv = BoxFilterConvolution(self.boxes,ogFilterSize,reg,device)\n",
    "#         for i,j in self.conv.named_parameters():\n",
    "#             print(i,j)\n",
    "#         self.fc = nn.Linear(1728,128)\n",
    "            \n",
    "\n",
    "#     # def forward(self,x):\n",
    "#     #     x = x.cumsum(dim=-2).cumsum(dim=-1)\n",
    "#     #     x = self.conv(x)\n",
    "#     #     x = x.to(torch.float)\n",
    "#     #     x = nn.Flatten()(x)\n",
    "#     #     x = self.fc(x)\n",
    "#     #     return x\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = x.cumsum(dim=-2).cumsum(dim=-1)\n",
    "#         return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxFiltersList = [[[0,2,0,2],[0,1,0,1],[0,2,2,2]]]\n",
    "# cBox = cnnBox(3,False,device,boxFiltersList,(3,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTempFilter(tempBoxFilterList):\n",
    "    tempFilter = np.zeros((3,3))\n",
    "    for i in range(0,len(tempBoxFilterList)):\n",
    "        for j in range(tempBoxFilterList[i].c,tempBoxFilterList[i].d+1):\n",
    "            for k in range(tempBoxFilterList[i].a,tempBoxFilterList[i].b+1):\n",
    "                #print(j,k)\n",
    "                tempFilter[j][k] = tempFilter[j][k] + tempBoxFilterList[i].alpha\n",
    "\n",
    "    return tempFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_box_coordinates(kernel_size):\n",
    "    coordinates = []\n",
    "    for a in range(kernel_size):\n",
    "        for b in range(a, kernel_size):\n",
    "            for c in range(kernel_size):\n",
    "                for d in range(c, kernel_size):\n",
    "                    coordinates.append([a, b, c, d])\n",
    "                    \n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_boxes = get_all_box_coordinates(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4356\n"
     ]
    }
   ],
   "source": [
    "print(len(all_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossFunc = nn.CrossEntropyLoss()\n",
    "\n",
    "# boxFiltersList = [[[0,1,0,1],[0,2,0,2],[0,3,0,3],[0,4,0,4],[1,3,1,3],[1,4,1,4],[2,4,2,4],[3,4,3,4],[0,4,0,0],[0,0,0,4],[2,2,0,4],[0,4,2,2]],\n",
    "#                  [[0,1,0,2],[0,2,0,3],[0,3,0,4],[0,4,0,1],[1,3,1,4],[1,4,1,0],[2,4,2,1],[3,4,3,2],[0,4,0,3],[0,0,0,2],[2,2,0,3],[0,4,2,1]],\n",
    "#                   [[0,1,0,3],[0,2,0,4],[0,3,0,1],[0,4,0,2],[1,3,1,0],[1,4,1,2],[2,4,2,3],[3,4,3,0],[0,4,0,1],[0,0,0,3],[2,2,0,1],[0,4,2,3]]]\n",
    "\n",
    "# cBox = cnnBox(12,False,device,boxFiltersList,(5,5,3))\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# cBox.to(device)\n",
    "# optimizer = optim.SGD(cBox.parameters(), lr=0.01)\n",
    "\n",
    "# # Train the network\n",
    "# for epoch in range(20):  # 10 epochs\n",
    "#     totalLoss = 0\n",
    "#     for images, labels in trainloader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = cBox(images)\n",
    "        \n",
    "#         loss = nn.CrossEntropyLoss()(output, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         totalLoss = totalLoss + loss.item()\n",
    "    \n",
    "#     print(f\"Epoch {epoch+1} completed\",totalLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = torch.load(\"./input_images.pt\")\n",
    "feature_maps = torch.load(\"./feature_maps.pt\").permute(1, 0, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define a custom Dataset class\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, feature_map, input_image):\n",
    "        self.feature_map = feature_map\n",
    "        self.input_image = input_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.feature_map.size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.feature_map[idx], self.input_image[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureMap = feature_maps.detach()\n",
    "inputs = input_images.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the custom dataset\n",
    "dataset = TensorDataset(featureMap[:,0,:,:].unsqueeze(1), inputs)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed with loss: 7.691158294677734\n",
      "Epoch 2 completed with loss: 0.9019960761070251\n",
      "Epoch 3 completed with loss: 0.5227681398391724\n",
      "Epoch 4 completed with loss: 0.485098272562027\n",
      "Epoch 5 completed with loss: 0.476893812417984\n",
      "Epoch 6 completed with loss: 0.4731825292110443\n",
      "Epoch 7 completed with loss: 0.466644823551178\n",
      "Epoch 8 completed with loss: 0.48192280530929565\n",
      "Epoch 9 completed with loss: 0.458503782749176\n",
      "Epoch 10 completed with loss: 0.46594440937042236\n"
     ]
    }
   ],
   "source": [
    "boxFiltersList = get_all_box_coordinates(11)\n",
    "model = cnnBox(len(boxFiltersList),1,False,device, boxFiltersList,11)\n",
    "#print(len(boxFiltersList),len(boxFiltersList[0]),len(boxFiltersList[0][0]))\n",
    "#return\n",
    "EPOCHS = 10\n",
    "LAMBDA = 0.0001\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in dataloader:\n",
    "        ft_maps, inp_imgs = batch\n",
    "        \n",
    "        box_model_op = model(inp_imgs)\n",
    "        \n",
    "        #print(\"inp:\",inp_imgs.shape,ft_maps.shape,box_model_op.shape)\n",
    "        loss = criterion(box_model_op, ft_maps)\n",
    "\n",
    "        l1_penalty = sum(torch.abs(param).sum() for param in model.parameters())\n",
    "        loss += LAMBDA * l1_penalty\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} completed with loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4356"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxFiltersList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_batch = next(iter(dataloader))\n",
    "example_ft_maps, example_inp_imgs = example_batch\n",
    "\n",
    "def plot_feature_maps(feature_maps, title):\n",
    "    num_feature_maps = feature_maps[:4].shape[0]\n",
    "    fig, axes = plt.subplots(1, num_feature_maps, figsize=(15, 4))\n",
    "    for i in range(num_feature_maps):\n",
    "        axes[i].imshow(feature_maps[i, 0].detach().cpu().numpy())\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the example input image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(example_inp_imgs[0].detach().cpu().numpy().transpose(1, 2, 0), cmap='gray')\n",
    "# plt.title('Input Image')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# Plot the example feature maps\n",
    "example_output = model(example_inp_imgs)\n",
    "plot_feature_maps(example_ft_maps, 'Feature Maps (Ground Truth)')\n",
    "plot_feature_maps(example_output, 'Feature Maps (Model Output)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1533\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i,j in model.named_parameters():\n",
    "    if(abs(j.item())<0.0001):\n",
    "       count = count + 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.data = torch.where(torch.abs(param.data) < 0.0001, torch.zeros_like(param.data), param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLoss=0\n",
    "for batch in dataloader:\n",
    "        ft_maps, inp_imgs = batch\n",
    "        \n",
    "        box_model_op = model(inp_imgs)\n",
    "        print(criterion(box_model_op, ft_maps))\n",
    "        #print(\"inp:\",inp_imgs.shape,ft_maps.shape,box_model_op.shape)\n",
    "        #totalLoss = totalLoss + criterion(box_model_op, ft_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTempFilter(tempBoxFilterList):\n",
    "    tempFilter = np.zeros((11,11))\n",
    "    for i in range(0,len(tempBoxFilterList)):\n",
    "        for j in range(tempBoxFilterList[i].c,tempBoxFilterList[i].d+1):\n",
    "            for k in range(tempBoxFilterList[i].a,tempBoxFilterList[i].b+1):\n",
    "                #print(j,k)\n",
    "                tempFilter[j][k] = tempFilter[j][k] + tempBoxFilterList[i].alpha\n",
    "\n",
    "    return tempFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_filter = torch.tensor([[-0.0225,  0.2035,  0.0672,  0.1836, -0.2526],\n",
    "#         [-0.1349,  0.1441,  0.0781,  0.0347, -0.3479],\n",
    "#         [-0.0598,  0.1090,  0.0902, -0.1602, -0.0176],\n",
    "#         [-0.0561,  0.1678,  0.0149, -0.0683,  0.0802],\n",
    "#         [-0.0414,  0.1663,  0.0753,  0.3775,  0.0611]])\n",
    "temp_filter = computeTempFilter(model.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(dataloader))\n",
    "example_ft_maps, example_inp_imgs = example_batch\n",
    "\n",
    "example_inp_imgs = example_inp_imgs.to(device)\n",
    "\n",
    "def plot_feature_maps(feature_maps, title):\n",
    "    num_feature_maps = feature_maps[:4].shape[0]\n",
    "    fig, axes = plt.subplots(1, num_feature_maps, figsize=(15, 4))\n",
    "    for i in range(num_feature_maps):\n",
    "        axes[i].imshow(feature_maps[i, 0].detach().cpu().numpy())\n",
    "        axes[i].axis('off')\n",
    "    fig.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the example input image\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(example_inp_imgs[0].detach().cpu().numpy().transpose(1, 2, 0), cmap='gray')\n",
    "# plt.title('Input Image')\n",
    "# plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# Plot the example feature maps\n",
    "example_output = model(example_inp_imgs)\n",
    "plot_feature_maps(example_ft_maps, 'Feature Maps (Ground Truth)')\n",
    "plot_feature_maps(example_output, 'Feature Maps (Model Output)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1033, dtype=torch.float64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.L1Loss()(torch.tensor(temp_filter), original_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.CIFAR10('~/.pytorch/CIFAR/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.CIFAR10('~/.pytorch/CIFAR/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 3, 11)  # 1 input channel, 6 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(3, 3, 11)\n",
    "        self.fc = nn.Linear(432, 10)  # 10 classes for MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        #x = x.view(-1, 36864)  # Flatten the tensor\n",
    "        #print(x.shape)\n",
    "        x = x.flatten(1)  # Flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the network and optimizer\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Net()\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(10):  # 10 epochs\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = nn.CrossEntropyLoss()(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 37 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient computation\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = None\n",
    "for images, labels in testloader:\n",
    "    if(input==None):\n",
    "        input = images\n",
    "    else:\n",
    "        input = torch.cat((input,images),0)\n",
    "\n",
    "input=input.to(device)\n",
    "featureMap = model.conv1(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 28, 28])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureMap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model.eval()\n",
    "count = 0\n",
    "weight = None\n",
    "for i,j in model.named_parameters():\n",
    "  if(count>0):\n",
    "    break\n",
    "  print(i)\n",
    "  weight = j\n",
    "  count = count + 1\n",
    "weight[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
